<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Deep inference | Matteo Priorelli</title> <meta name="author" content="Matteo Priorelli"> <meta name="description" content="kinematic inference in hierarchical models, intrinsic and extrinsic intentions, human kinematics, obstacle avoidance"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.jpg?d51b3988f719277b5e0b7ca3e96e79b5"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://priorelli.github.io/projects/2_deep_inference/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?ccb5eeb538e8a79969e344d3d49ba566"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">MatteoÂ </span>Priorelli</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deep inference</h1> <p class="post-description">kinematic inference in hierarchical models, intrinsic and extrinsic intentions, human kinematics, obstacle avoidance</p> </header> <article> <p align="center"> <img src="/assets/img/deep_inference.png"> </p> <p>This is the project related to the paper <a href="https://doi.org/10.1073/pnas.2309058120" rel="external nofollow noopener" target="_blank">Deep kinematic inference affords efficient and scalable control of bodily movements</a>. It describes an active inference model that affords a simple but effective mapping from extrinsic to intrinsic coordinates via inference, and easily scales up to drive complex kinematic chains. The proposed model can realize a variety of tasks such as tracking a target while avoiding an obstacle, making lateral movements while maintaining a vertical orientation, performing circular movements; it can also deal with human-body kinematics or complex trees with multiple ramifications. The paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-47958-8_5" rel="external nofollow noopener" target="_blank">Efficient motor learning through action-perception cycles in deep kinematic inference</a> extends this model with an algorithms that allows to learn the kinematic chain during goal-directed behavior.</p> <p>The code can be found <a href="https://github.com/priorelli/deep-kinematic-inference" rel="external nofollow noopener" target="_blank">here</a>.</p> <h2 id="video-simulations">Video simulations</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/ZdVVoviCZcA" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/U4pvpnHQ37g" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> <div class="caption"> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/6fDP4A-HAkc" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/8NqP-q1CHJ4" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> <div class="caption"> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/p6KRFFCmarg" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/zqP8_WYqhBM" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> <div class="caption"> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://youtube.com/embed/AbMZrZuBbLY" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> <div class="caption"> </div> <h2 id="howto">HowTo</h2> <h3 id="start-the-simulation">Start the simulation</h3> <p>All the simulations of the paper are located in the folder <em>demos/</em>.</p> <p>The simulation can be launched through <em>main.py</em>, either with the option <code class="language-plaintext highlighter-rouge">-m</code> for manual control, <code class="language-plaintext highlighter-rouge">-s</code> for the IE (shallow) model, <code class="language-plaintext highlighter-rouge">-d</code> for the deep hierarchical model (deep), <code class="language-plaintext highlighter-rouge">-j</code> for the standard Jacobian control, or <code class="language-plaintext highlighter-rouge">-a</code> for choosing the parameters from the console. If no option is specified, the last one will be launched. For the manual control simulation, the arm can be moved with the keys <code class="language-plaintext highlighter-rouge">Z</code>, <code class="language-plaintext highlighter-rouge">X</code>, <code class="language-plaintext highlighter-rouge">A</code>, <code class="language-plaintext highlighter-rouge">S</code>, <code class="language-plaintext highlighter-rouge">LEFT</code>, <code class="language-plaintext highlighter-rouge">RIGHT</code>, <code class="language-plaintext highlighter-rouge">UP</code> and <code class="language-plaintext highlighter-rouge">DOWN</code>.</p> <p>Plots can be generated through <em>plot.py</em>, either with the option <code class="language-plaintext highlighter-rouge">-d</code> for the belief trajectories, <code class="language-plaintext highlighter-rouge">-s</code> for the scores, or <code class="language-plaintext highlighter-rouge">-v</code> for generating a video of the simulation.</p> <p>The folder <em>reference/video/</em> contains a few videos about the applications described in the paper.</p> <h3 id="advanced-configuration">Advanced configuration</h3> <p>More advanced parameters can be manually set from <em>config.py</em>. Custom log names are set with the variable <code class="language-plaintext highlighter-rouge">log_name</code>. The number of trials and steps can be set with the variables <code class="language-plaintext highlighter-rouge">n_trials</code> and <code class="language-plaintext highlighter-rouge">n_steps</code>, respectively.</p> <p>The parameter <code class="language-plaintext highlighter-rouge">lr_length</code> controls the learning rate of the length beliefs. If it is set to 0, these beliefs will not be updated.</p> <p>The parameters <code class="language-plaintext highlighter-rouge">k_rep</code> and <code class="language-plaintext highlighter-rouge">avoid_dist</code> respectively control the gain of the repulsive force, and the distance after which the force cannot affect the agent.</p> <p>Different precisions have been used for the shallow and deep models: for the former, the visual precision <code class="language-plaintext highlighter-rouge">pi_vis</code> has been set to 1.0, while the extrinsic precision <code class="language-plaintext highlighter-rouge">pi_ext</code> to 0.05; for the latter, the visual precision <code class="language-plaintext highlighter-rouge">pi_vis</code> has been set to 0.1, while the extrinsic precision <code class="language-plaintext highlighter-rouge">pi_ext</code> to 0.5.</p> <p>The variable <code class="language-plaintext highlighter-rouge">task</code> affects the goal of the active inference agent, and can assume the following values:</p> <ol> <li> <code class="language-plaintext highlighter-rouge">reach</code>: an intention to reach a red target is set at the last level. This corresponds to the reach and track tasks;</li> <li> <code class="language-plaintext highlighter-rouge">avoid</code>: an intention to avoid a green obstacle is set at every level. This corresponds to the avoid task;</li> <li> <code class="language-plaintext highlighter-rouge">both</code>: the first two conditions are active simultaneously. This corresponds to the reach and avoid, and track and avoid tasks;</li> <li> <code class="language-plaintext highlighter-rouge">infer</code>: the proprioceptive precision <code class="language-plaintext highlighter-rouge">pi_prop</code> is set to 0, and a random arm configuration is set at every trial. This has been used to assess perceptual performances (e.g., in Figure 2B).</li> </ol> <p>The variable <code class="language-plaintext highlighter-rouge">context</code> specifies whether (<code class="language-plaintext highlighter-rouge">dynamic</code>) or not (<code class="language-plaintext highlighter-rouge">static</code>) the red target and the green obstacle move. The velocity is set by <code class="language-plaintext highlighter-rouge">target_vel</code>.</p> <p>The agent configuration is defined through the dictionary <code class="language-plaintext highlighter-rouge">joints</code>. The value <code class="language-plaintext highlighter-rouge">link</code> specifies the joint to which the new one is attached; <code class="language-plaintext highlighter-rouge">angle</code> encodes the starting value of the joint; <code class="language-plaintext highlighter-rouge">limit</code> defines the min and max angle limits.</p> <p>If needed, target and obstacle positions and directions (encoded in the arrays <code class="language-plaintext highlighter-rouge">obj_pos</code> and <code class="language-plaintext highlighter-rouge">obj_dirs</code>) can be manually through the function <code class="language-plaintext highlighter-rouge">sample_objects</code> in <em>environment/window.py</em>.</p> <h3 id="agent">Agent</h3> <p>The script <em>simulation/inference.py</em> contains a subclass of <code class="language-plaintext highlighter-rouge">Window</code> in <em>environment/window.py</em>, which is in turn a subclass <code class="language-plaintext highlighter-rouge">pyglet.window.Window</code>. The only overriden function is <code class="language-plaintext highlighter-rouge">update</code>, which defines the instructions to run in a single cycle. Specifically, the subclass <code class="language-plaintext highlighter-rouge">Inference</code> initializes the agent and the objects; during each update, it retrieves proprioceptive and visual observations through functions defined in <em>environment/window.py</em>, calls the function <code class="language-plaintext highlighter-rouge">inference_step</code> of the agent, and finally moves the arm and the objects.</p> <p>There are three different classes for the agents, corresponding to the shallow, deep, or jacobian models. All of them have a similar function <code class="language-plaintext highlighter-rouge">inference_step</code>. In particular, the function <code class="language-plaintext highlighter-rouge">get_p</code> returns visual (Cartesian position) and proprioceptive (joint angle) predictions, and an additional extrinsic (Cartesian position and absolute orientation) prediction for the shallow and deep models. The function <code class="language-plaintext highlighter-rouge">get_i</code> returns intrinsic and extrinsic future beliefs depending on the agentâs intentions, e.g., reach a Cartesian position or an angle with a specific joint. Note that for simplicity desired target joints and positions are directly provided as input to the function, but they could also be inferred through sensory observations. Functions <code class="language-plaintext highlighter-rouge">get_e_g</code> and <code class="language-plaintext highlighter-rouge">get_e_mu</code> compute sensory and dynamics prediction errors, respectively. The function <code class="language-plaintext highlighter-rouge">get_likelihood</code> backpropagates the sensory errors toward the beliefs, calling the function <code class="language-plaintext highlighter-rouge">grad_ext</code> to compute the extrinsic gradient, which is also used for learning of limb lengths. Note that in the deep model each joint is affected by the likelihoods <code class="language-plaintext highlighter-rouge">lkh_ext</code> of all the joints it is attached to. Note also that the proprioceptive prediction error is not used for assessing performances during inference only. Finally, the function <code class="language-plaintext highlighter-rouge">mu_dot</code> computes the total belief updates, also considering the backward and forward errors <code class="language-plaintext highlighter-rouge">E_mu</code> of the dynamics functions and, in the shallow and deep models, the repulsive forces computed through <code class="language-plaintext highlighter-rouge">get_rep_force</code>.</p> <p>Limb lengths can be initialized through the function <code class="language-plaintext highlighter-rouge">init_belief</code>.</p> <p>Useful trajectories computed during the simulations are stored through the class <code class="language-plaintext highlighter-rouge">Log</code> in <em>environment/log.py</em>.</p> <p>Note that all the variables are normalized between -1 and 1 to ensure that every contribution to the belief updates has the same magnitude.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Priorelli2023d" class="col-sm-8"> <div class="title">Efficient Motor Learning Through Action-Perception Cycles inÂ Deep Kinematic Inference</div> <div class="author"> <em>Matteo Priorelli</em>,Â andÂ Ivilin Peev Stoianov</div> <div class="periodical"> <em></em> 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Priorelli2023e" class="col-sm-8"> <div class="title">Deep kinematic inference affords efficient and scalable control of bodily movements</div> <div class="author"> <em>Matteo Priorelli</em>,Â Giovanni Pezzulo,Â andÂ Ivilin Peev Stoianov</div> <div class="periodical"> <em>PNAS</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Matteo Priorelli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>