<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Flexible intentions | Matteo Priorelli</title> <meta name="author" content="Matteo Priorelli"> <meta name="description" content="dynamic behavior, multisensory integration, object tracking"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.jpg?d51b3988f719277b5e0b7ca3e96e79b5"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://priorelli.github.io/projects/1_flexible_intentions/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?ccb5eeb538e8a79969e344d3d49ba566"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Matteo </span>Priorelli</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Flexible intentions</h1> <p class="post-description">dynamic behavior, multisensory integration, object tracking</p> </header> <article> <p align="center"> <img src="/assets/img/flexible_intentions.png"> </p> <p>This is the project related to the paper <a href="https://www.frontiersin.org/articles/10.3389/fncom.2023.1128694/full" rel="external nofollow noopener" target="_blank">Flexible Intentions: An Active Inference Theory</a>. It contains a proposal about encoding environmental entities (e.g., a target to reach or a previously memorized home button) and realizing dynamic goal-directed behavior such as object tracking, and some analyses on multisensory integration for movements. The paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-28719-0_19" rel="external nofollow noopener" target="_blank">Intention Modulation for Multi-step Tasks in Continuous Time Active Inference</a> extends this model by introducing a fixed multi-step behavior (e.g., reaching multiple target positions in sequence). The code can be found <a href="https://github.com/priorelli/PACE" rel="external nofollow noopener" target="_blank">here</a>.</p> <h2 id="howto">HowTo</h2> <h3 id="start-the-simulation">Start the simulation</h3> <p>The simulation can be launched through <em>main.py</em>, either with the option <code class="language-plaintext highlighter-rouge">-m</code> for manual control, <code class="language-plaintext highlighter-rouge">-s</code> for the active inference agent with default parameters, or <code class="language-plaintext highlighter-rouge">-a</code> for choosing the parameters from the console. If no option is specified, the last one will be launched. For the manual control simulation, the arm can be moved with the keys <code class="language-plaintext highlighter-rouge">Z</code>, <code class="language-plaintext highlighter-rouge">X</code>, <code class="language-plaintext highlighter-rouge">LEFT</code>, <code class="language-plaintext highlighter-rouge">RIGHT</code>, <code class="language-plaintext highlighter-rouge">UP</code> and <code class="language-plaintext highlighter-rouge">DOWN</code>.</p> <p>The dataset for the VAE is generated through the option <code class="language-plaintext highlighter-rouge">-g</code>, while <code class="language-plaintext highlighter-rouge">-t</code> will run a benchmark test on the trained VAE. For each datapoint, a random target size is sampled from the variable <code class="language-plaintext highlighter-rouge">target_min_max</code> in <em>config.py</em>.</p> <p>Plots can be generated through <em>plot.py</em>, either with the option <code class="language-plaintext highlighter-rouge">-a</code> for the free energy derivatives, <code class="language-plaintext highlighter-rouge">-d</code> for the belief trajectories, <code class="language-plaintext highlighter-rouge">-f</code> for the final positions of the hand, <code class="language-plaintext highlighter-rouge">-g</code> for the VAE gradients, <code class="language-plaintext highlighter-rouge">-p</code> for angles and velocities, <code class="language-plaintext highlighter-rouge">-s</code> for the scores, or <code class="language-plaintext highlighter-rouge">-v</code> for generating a video of the simulation.</p> <p>The folder <em>reference/video/</em> contains a few videos about target tracking, movements with or without visual input, and dynamic onset policy.</p> <h3 id="advanced-configuration">Advanced configuration</h3> <p>More advanced parameters can be manually set from <em>config.py</em>. Custom log names are set with the variable <code class="language-plaintext highlighter-rouge">log_name</code>. The number of trials and steps can be set with the variables <code class="language-plaintext highlighter-rouge">n_trials</code> and <code class="language-plaintext highlighter-rouge">n_steps</code>, respectively.</p> <p>Both the target positions and the home button are stored in joint angle coordinates, the former in the list <code class="language-plaintext highlighter-rouge">targets</code> and the latter by the variable <code class="language-plaintext highlighter-rouge">home</code>.</p> <p>The variable <code class="language-plaintext highlighter-rouge">task</code> affects the generation of target positions, and can assume the following values:</p> <ol> <li> <code class="language-plaintext highlighter-rouge">test</code>: generates random target positions at each trial - see Figure 7;</li> <li> <code class="language-plaintext highlighter-rouge">all</code>: generates the simulation used for Figure 6, i.e., one of the 9 fixed target positions of Figure 3A, followed by the home button position. The variable <code class="language-plaintext highlighter-rouge">n_reps</code> denotes the number of repetition per target position;</li> <li> <code class="language-plaintext highlighter-rouge">single</code>: fixes the target to one of the 9 positions, for all trials. This position can be set with the function <code class="language-plaintext highlighter-rouge">set_trajectory</code> in <em>simulation/inference.py</em>.</li> </ol> <p>The variable <code class="language-plaintext highlighter-rouge">context</code> specifies whether (<code class="language-plaintext highlighter-rouge">dynamic</code>) or not (<code class="language-plaintext highlighter-rouge">static</code>) the target moves. The target velocity is set by <code class="language-plaintext highlighter-rouge">target_vel</code>.</p> <p>The variable <code class="language-plaintext highlighter-rouge">phases</code> chooses the movement onset policy of the agent (<code class="language-plaintext highlighter-rouge">immediate</code>, <code class="language-plaintext highlighter-rouge">fixed</code>, or <code class="language-plaintext highlighter-rouge">dynamic</code>) as defined in the paper.</p> <p>The arm configuration is defined through the dictionary <code class="language-plaintext highlighter-rouge">joints</code>. The value <code class="language-plaintext highlighter-rouge">link</code> specifies the joint to which the new one is attached; <code class="language-plaintext highlighter-rouge">angle</code> encodes the starting value of the joint; <code class="language-plaintext highlighter-rouge">limit</code> defines the min and max angle limits.</p> <h3 id="active-inference">Active inference</h3> <p>The active inference simulation involves the scripts <em>simulation/inference.py</em> and <em>simulation/agent.py</em>. The former contains a subclass of <code class="language-plaintext highlighter-rouge">Window</code> in <em>environment/window.py</em>, which is in turn a subclass <code class="language-plaintext highlighter-rouge">pyglet.window.Window</code>. The only overriden function is <code class="language-plaintext highlighter-rouge">update</code>, which defines the instructions to run in a single cycle. Specifically, the subclass <code class="language-plaintext highlighter-rouge">Inference</code> initializes the agent and the sequence of target positions; during each update, it retrieves proprioceptive and visual observations through functions defined in <em>environment/window.py</em>, calls the function <code class="language-plaintext highlighter-rouge">inference_step</code> of <em>simulation/agent.py</em>, and finally moves the arm and the target.</p> <p>The function <code class="language-plaintext highlighter-rouge">inference_step</code> of the class <code class="language-plaintext highlighter-rouge">Agent</code> in <em>simulation/agent.py</em> contains all the instructions of Algorithm 1. In particular, the function <code class="language-plaintext highlighter-rouge">get_p</code> returns a visual prediction through the VAE, and a proprioceptive prediction through the matrix <code class="language-plaintext highlighter-rouge">G_p</code>. Note that the input and output of the VAE is stored in an additional list, which is needed for the successive error backpropagation. Note also this function returns a velocity prediction <code class="language-plaintext highlighter-rouge">p_vel</code>, which however is not used in the analyses of the paper. The function <code class="language-plaintext highlighter-rouge">get_h</code> returns future beliefs computed through the intention matrices stored in <code class="language-plaintext highlighter-rouge">I</code> (encoding <code class="language-plaintext highlighter-rouge">I_t</code> and <code class="language-plaintext highlighter-rouge">I_h</code> of the paper). The list <code class="language-plaintext highlighter-rouge">I</code> can thus be used to realize custom dynamic behaviors. Functions <code class="language-plaintext highlighter-rouge">get_e_s</code> and <code class="language-plaintext highlighter-rouge">get_e_mu</code> compute sensory and dynamics prediction error, respectively. The function <code class="language-plaintext highlighter-rouge">get_likelihood</code> backpropagates the sensory errors toward the belief, multiplying them by the precisions encoded in the list <code class="language-plaintext highlighter-rouge">pi_s</code> and the variable <code class="language-plaintext highlighter-rouge">alpha</code>. Finally, the function <code class="language-plaintext highlighter-rouge">mu_dot</code> computes the total belief update, also considering the backward and forward errors of the dynamics function.</p> <p>Useful trajectories computed during the simulations are stored through the class <code class="language-plaintext highlighter-rouge">Log</code> in <em>environment/log.py</em>.</p> <p>Note that all the variables are normalized between 0 and 1 to ensure that every contribution to the belief updates has the same magnitude.</p> <p><br></p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Priorelli2023a" class="col-sm-8"> <div class="title">Flexible Intentions : An Active Inference Theory</div> <div class="author"> <em>Matteo Priorelli</em>, and Ivilin Peev Stoianov</div> <div class="periodical"> <em>Frontiers in Computational Neuroscience</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Priorelli2023b" class="col-sm-8"> <div class="title">Intention Modulation for Multi-step Tasks in Continuous Time Active Inference</div> <div class="author"> <em>Matteo Priorelli</em>, and Ivilin Peev Stoianov</div> <div class="periodical"> <em>Communications in Computer and Information Science</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Matteo Priorelli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>